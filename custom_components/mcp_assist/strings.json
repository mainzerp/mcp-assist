{
  "config": {
    "step": {
      "user": {
        "title": "Profile Setup",
        "description": "Create a new agent profile with a unique name and personality.",
        "data": {
          "profile_name": "Profile Name",
          "server_type": "Server Type"
        }
      },
      "server": {
        "title": "Server Configuration",
        "description": "Configure your inference server URL and MCP server port.",
        "data": {
          "lmstudio_url": "Server URL",
          "api_key": "API Key",
          "mcp_port": "MCP Server Port"
        }
      },
      "model": {
        "title": "Model & Prompts",
        "description": "Select a model and customize the system prompt. Models are automatically loaded from your server.",
        "data": {
          "model_name": "Model Name",
          "system_prompt": "System Prompt",
          "technical_prompt": "Technical Instructions"
        }
      },
      "advanced": {
        "title": "Advanced Settings",
        "description": "Configure temperature, token limits, and other advanced options.",
        "data": {
          "temperature": "Temperature",
          "max_tokens": "Max Response Tokens",
          "max_history": "Max History Messages",
          "max_iterations": "Max Tool Iterations",
          "control_home_assistant": "Control Home Assistant",
          "response_mode": "Response Mode",
          "debug_mode": "Debug Mode",
          "ollama_keep_alive": "Ollama Keep Alive",
          "ollama_num_ctx": "Ollama Context Window",
          "enable_pre_resolve": "Enable Entity Pre-Resolution",
          "pre_resolve_threshold": "Pre-Resolution Similarity Threshold",
          "enable_fast_path": "Enable Fast Path",
          "fast_path_language": "Fast Path Language",
          "enable_parallel_tools": "Enable Parallel Tool Execution"
        }
      },
      "mcp_server": {
        "title": "Shared MCP Server Settings",
        "description": "⚠️ These settings affect ALL profiles. Changes here will impact every MCP Assist conversation agent.",
        "data": {
          "mcp_port": "MCP Server Port",
          "search_provider": "Web Search",
          "brave_api_key": "Brave Search API Key",
          "allowed_ips": "Additional Allowed IPs/Ranges",
          "enable_gap_filling": "Enable Smart Entity Index"
        }
      }
    },
    "error": {
      "cannot_connect": "Cannot connect to the inference server. Make sure it's running and accessible.",
      "no_models": "No models loaded on the server. Please load a model first.",
      "invalid_model": "The specified model is not available on the server.",
      "invalid_port": "Port must be between 1024 and 65535.",
      "invalid_ip": "Invalid IP address or CIDR range format. Use comma-separated values like: 172.30.0.0/16, 192.168.1.100",
      "profile_name_required": "Profile name is required.",
      "invalid_json": "Invalid JSON format. Please check your MCP servers configuration.",
      "invalid_api_key": "Invalid API key. Please check and try again.",
      "auth_failed": "Authentication failed. Please verify your API key.",
      "unknown": "An unknown error occurred."
    },
    "abort": {
      "already_configured": "A profile with this name already exists. Please choose a different name."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Profile Settings",
        "description": "Configure this conversation profile. These settings only affect this profile.",
        "data": {
          "profile_name": "Profile Name",
          "lmstudio_url": "Server URL",
          "api_key": "API Key",
          "model_name": "Model Name",
          "system_prompt": "System Prompt",
          "technical_prompt": "Technical Instructions",
          "temperature": "Temperature",
          "max_tokens": "Max Response Tokens",
          "max_history": "Max History Messages",
          "max_iterations": "Max Tool Iterations",
          "control_home_assistant": "Control Home Assistant",
          "response_mode": "Response Mode",
          "debug_mode": "Debug Mode",
          "ollama_keep_alive": "Ollama Keep Alive",
          "ollama_num_ctx": "Ollama Context Window",
          "enable_pre_resolve": "Enable Entity Pre-Resolution",
          "pre_resolve_threshold": "Pre-Resolution Similarity Threshold",
          "enable_fast_path": "Enable Fast Path",
          "fast_path_language": "Fast Path Language",
          "enable_parallel_tools": "Enable Parallel Tool Execution"
        }
      },
      "mcp_server": {
        "title": "Shared MCP Server Settings",
        "description": "⚠️ These settings are shared across ALL profiles",
        "data": {
          "mcp_port": "MCP Server Port",
          "search_provider": "Web Search",
          "brave_api_key": "Brave Search API Key",
          "allowed_ips": "Additional Allowed IPs/Ranges",
          "enable_gap_filling": "Enable Smart Entity Index"
        }
      }
    }
  },
  "entity": {
    "conversation": {
      "mcp_assist": {
        "name": "{profile_name}"
      }
    },
    "sensor": {
      "status": {
        "name": "Status"
      },
      "fast_path_avg_response_time": {
        "name": "Fast Path Avg Response Time"
      },
      "llm_avg_response_time": {
        "name": "LLM Avg Response Time"
      },
      "fast_path_rate": {
        "name": "Fast Path Rate"
      },
      "fast_path_hits": {
        "name": "Fast Path Hits"
      },
      "pre_resolve_rate": {
        "name": "Pre-Resolve Rate"
      },
      "llm_calls_today": {
        "name": "LLM Calls Today"
      },
      "tokens_used_today": {
        "name": "Tokens Used Today"
      },
      "requests_today": {
        "name": "Requests Today"
      },
      "indexed_entities": {
        "name": "Indexed Entities"
      },
      "llm_errors": {
        "name": "LLM Errors"
      },
      "parallel_tool_batches": {
        "name": "Parallel Tool Batches"
      },
      "avg_parallel_batch_size": {
        "name": "Avg Parallel Batch Size"
      },
      "parallel_time_saved_ms": {
        "name": "Parallel Time Saved"
      }
    }
  }
}